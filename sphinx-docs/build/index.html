

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Object Recognition and Perception (ORP) documentation &mdash; ORP 1.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Markdown Formatting" href="markdown_pages.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> ORP
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="markdown_pages.html">Markdown Formatting</a></li>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="extending.html">Extending ORP</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">List of reference material</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">ORP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Object Recognition and Perception (ORP) documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="object-recognition-and-perception-orp-documentation">
<h1>Object Recognition and Perception (ORP) documentation<a class="headerlink" href="#object-recognition-and-perception-orp-documentation" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>ORP is an object recognition library for detecting objects using visual data
(such as information from 2D or 3D cameras). ORP bridges the gap between camera
data and useful information that your robotics application can use. It provides
the following features:</p>
<blockquote>
<div><ul class="simple">
<li>A unified framework for different types of visual object detectors</li>
<li>Handling of both 2D and 3D data</li>
<li>A YAML-based syntax for defining objects detectable with vision</li>
<li>An extendable set of basic classifier types</li>
<li>Example classifiers</li>
<li>A segmentation server that provides tunable versions of common algorithms provided by the Point Cloud library</li>
<li>Interoperability with <code class="docutils literal notranslate"><span class="pre">tf</span></code>, <code class="docutils literal notranslate"><span class="pre">rqt_reconfigure</span></code>, and (coming soon) <code class="docutils literal notranslate"><span class="pre">vision_msgs</span></code></li>
<li>Automatic RViz visualization of detected objects</li>
</ul>
</div></blockquote>
<p>We realize that every vision use case is different, so a key feature of ORP is
the ability to be easily modified, including tuning recognition algorithm
parameters. ORP uses functionality from the Point Cloud Library and OpenCV. If
you plan on extending or modifying ORP, you should have a good handle on at
least one of those two libraries.</p>
<p>Many features of ORP may seem outdated; this is partly intentional. While
machine learning-based computer vision has seen much success in recent years,
the needs of many robotics applications (such as locating a small object in a
fairly uncluttered environment) are often adequately met by using older vision
techniques, such as edge detection and clustering. With that being said,
because ORP is flexible and modular, it is possible to use newer detectors,
such as the YOLO detector, in the ORP framework, and in fact, it’s encouraged
because it allows visual classifiers to be more interoperable.</p>
</div>
<div class="section" id="structure">
<h2>Structure<a class="headerlink" href="#structure" title="Permalink to this headline">¶</a></h2>
<p>ORP is based on ROS, and each component of ORP is its own ROS node. These nodes
can each be modified, swapped, or configured separately, making ORP a powerful,
flexible tool for ROS-based recognition.</p>
<p>The key component of ORP is the <code class="docutils literal notranslate"><span class="pre">recognizer</span></code>, which aggregates vision
information from any number of classifiers. Classifers can be created by
writing a new C++ class that extends one of the provided Classifier base types,
such as Classifier2d (for image data) or Classifier3d (for point cloud data).
Other input types are also possible under the framework, just not strongly
supported yet.</p>
<p>ORP classifiers can be set to start recognizing as soon as they start, or they
can be started “dormant” and enabled later. You can debug ORP by using
rostopic echo on the /classification and /detected_objects topics.</p>
<p>ORP also provides a single node, the <em>segmentation server</em>, which provides many
point cloud processing algorithms out of the box, and has tunable parameters
exposed by the <code class="docutils literal notranslate"><span class="pre">rqt_reconfigure</span></code> ROS package.</p>
</div>
<div class="section" id="project-history">
<h2>Project History<a class="headerlink" href="#project-history" title="Permalink to this headline">¶</a></h2>
<p>ORP was originally conceived as part of Adam Allevato’s masters thesis,
published in 2016 at The University of Texas at Austin, for the Nuclear and
Applied Robotics group’s entry in the 2015 Amazon Picking Challenge.
Some of the code was based on earlier point cloud research done by Brian E.
O’Neil.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="markdown_pages.html" class="btn btn-neutral float-right" title="Markdown Formatting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>